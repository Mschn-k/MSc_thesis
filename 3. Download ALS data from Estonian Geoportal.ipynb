{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a9df45",
   "metadata": {},
   "source": [
    "# Save ALS point clouds from Estonian Land Board \n",
    "\n",
    "This notebook is for downloading point clouds from Estonian Land Board in .laz format and saving them to external harddrive. The point clouds are downloaded according to a .csv table that stores the map square number and the year of the point cloud needed. Map squares are 1:2000 map squares covering Estonia and how the national ALS data is structured. They can be downloaded from ELB website as a vector/feature layer. The map squares to be downloaded were selected in QGIS according to which have overlap with ICESat-2 transects with forest in them.\n",
    "\n",
    "The steps that were taken for retrieving the .csv file:\n",
    "* Add to QGIS: Hansen intact forest areas, tree species map, map squares, icesat transects' polygons\n",
    "* Select only the ICESat transects that are inside intact forest\n",
    "* Select map squares that have forested icesat transects in them using Extract by location tool.\n",
    "* Export the selected map squares as .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b79bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import os\n",
    "from urllib import request\n",
    "from urllib import error\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c4f01ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR</th>\n",
       "      <th>NR10000</th>\n",
       "      <th>ALS_AASTAD</th>\n",
       "      <th>ALS_TAVA_1</th>\n",
       "      <th>ALS_TAVA_2</th>\n",
       "      <th>ALS_TAVA_3</th>\n",
       "      <th>ALS_TAVA_4</th>\n",
       "      <th>ALS_MADAL</th>\n",
       "      <th>ALS_METS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>377650</td>\n",
       "      <td>44753</td>\n",
       "      <td>2019,2015,2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>377651</td>\n",
       "      <td>44753</td>\n",
       "      <td>2019,2015,2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>377652</td>\n",
       "      <td>44753</td>\n",
       "      <td>2019,2015,2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>377653</td>\n",
       "      <td>44753</td>\n",
       "      <td>2019,2015,2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>377655</td>\n",
       "      <td>44754</td>\n",
       "      <td>2019,2015,2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57861</th>\n",
       "      <td>616601</td>\n",
       "      <td>74103</td>\n",
       "      <td>2022,2018,2013,2009</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57862</th>\n",
       "      <td>616602</td>\n",
       "      <td>74103</td>\n",
       "      <td>2022,2018,2013,2009</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57913</th>\n",
       "      <td>617600</td>\n",
       "      <td>74103</td>\n",
       "      <td>2022,2018,2013,2009</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57914</th>\n",
       "      <td>617601</td>\n",
       "      <td>74103</td>\n",
       "      <td>2022,2018,2013,2009</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57932</th>\n",
       "      <td>618557</td>\n",
       "      <td>73154</td>\n",
       "      <td>2020,2013,2008</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45452 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           NR  NR10000           ALS_AASTAD  ALS_TAVA_1  ALS_TAVA_2  \\\n",
       "75     377650    44753       2019,2015,2011      2011.0      2015.0   \n",
       "76     377651    44753       2019,2015,2011      2011.0      2015.0   \n",
       "77     377652    44753       2019,2015,2011      2011.0      2015.0   \n",
       "78     377653    44753       2019,2015,2011      2011.0      2015.0   \n",
       "80     377655    44754       2019,2015,2011      2011.0      2015.0   \n",
       "...       ...      ...                  ...         ...         ...   \n",
       "57861  616601    74103  2022,2018,2013,2009      2009.0      2013.0   \n",
       "57862  616602    74103  2022,2018,2013,2009      2009.0      2013.0   \n",
       "57913  617600    74103  2022,2018,2013,2009      2009.0      2013.0   \n",
       "57914  617601    74103  2022,2018,2013,2009      2009.0      2013.0   \n",
       "57932  618557    73154       2020,2013,2008      2008.0      2013.0   \n",
       "\n",
       "       ALS_TAVA_3  ALS_TAVA_4  ALS_MADAL  ALS_METS  \n",
       "75         2019.0         NaN        NaN    2017.0  \n",
       "76         2019.0         NaN        NaN    2017.0  \n",
       "77         2019.0         NaN        NaN    2017.0  \n",
       "78         2019.0         NaN        NaN    2017.0  \n",
       "80         2019.0         NaN        NaN    2017.0  \n",
       "...           ...         ...        ...       ...  \n",
       "57861      2018.0      2022.0        NaN    2020.0  \n",
       "57862      2018.0      2022.0        NaN    2020.0  \n",
       "57913      2018.0      2022.0        NaN    2020.0  \n",
       "57914      2018.0      2022.0        NaN    2020.0  \n",
       "57932      2020.0         NaN        NaN    2018.0  \n",
       "\n",
       "[45452 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the .csv into a pandas dataframe\n",
    "als_list = pd.read_csv('..\\\\Data\\\\ALS_files_list.csv')\n",
    "als_list[als_list['ALS_METS'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28f8266e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NR</th>\n",
       "      <th>NR10000</th>\n",
       "      <th>ALS_AASTAD</th>\n",
       "      <th>ALS_TAVA_1</th>\n",
       "      <th>ALS_TAVA_2</th>\n",
       "      <th>ALS_TAVA_3</th>\n",
       "      <th>ALS_TAVA_4</th>\n",
       "      <th>ALS_MADAL</th>\n",
       "      <th>ALS_METS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>377650</td>\n",
       "      <td>44753</td>\n",
       "      <td>2019,2015,2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>377651</td>\n",
       "      <td>44753</td>\n",
       "      <td>2019,2015,2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>377652</td>\n",
       "      <td>44753</td>\n",
       "      <td>2019,2015,2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>377653</td>\n",
       "      <td>44753</td>\n",
       "      <td>2019,2015,2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>377655</td>\n",
       "      <td>44754</td>\n",
       "      <td>2019,2015,2011</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57861</th>\n",
       "      <td>616601</td>\n",
       "      <td>74103</td>\n",
       "      <td>2022,2018,2013,2009</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57862</th>\n",
       "      <td>616602</td>\n",
       "      <td>74103</td>\n",
       "      <td>2022,2018,2013,2009</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57913</th>\n",
       "      <td>617600</td>\n",
       "      <td>74103</td>\n",
       "      <td>2022,2018,2013,2009</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57914</th>\n",
       "      <td>617601</td>\n",
       "      <td>74103</td>\n",
       "      <td>2022,2018,2013,2009</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57932</th>\n",
       "      <td>618557</td>\n",
       "      <td>73154</td>\n",
       "      <td>2020,2013,2008</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45452 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           NR  NR10000           ALS_AASTAD  ALS_TAVA_1  ALS_TAVA_2  \\\n",
       "75     377650    44753       2019,2015,2011      2011.0      2015.0   \n",
       "76     377651    44753       2019,2015,2011      2011.0      2015.0   \n",
       "77     377652    44753       2019,2015,2011      2011.0      2015.0   \n",
       "78     377653    44753       2019,2015,2011      2011.0      2015.0   \n",
       "80     377655    44754       2019,2015,2011      2011.0      2015.0   \n",
       "...       ...      ...                  ...         ...         ...   \n",
       "57861  616601    74103  2022,2018,2013,2009      2009.0      2013.0   \n",
       "57862  616602    74103  2022,2018,2013,2009      2009.0      2013.0   \n",
       "57913  617600    74103  2022,2018,2013,2009      2009.0      2013.0   \n",
       "57914  617601    74103  2022,2018,2013,2009      2009.0      2013.0   \n",
       "57932  618557    73154       2020,2013,2008      2008.0      2013.0   \n",
       "\n",
       "       ALS_TAVA_3  ALS_TAVA_4  ALS_MADAL  ALS_METS  \n",
       "75         2019.0         NaN        NaN    2017.0  \n",
       "76         2019.0         NaN        NaN    2017.0  \n",
       "77         2019.0         NaN        NaN    2017.0  \n",
       "78         2019.0         NaN        NaN    2017.0  \n",
       "80         2019.0         NaN        NaN    2017.0  \n",
       "...           ...         ...        ...       ...  \n",
       "57861      2018.0      2022.0        NaN    2020.0  \n",
       "57862      2018.0      2022.0        NaN    2020.0  \n",
       "57913      2018.0      2022.0        NaN    2020.0  \n",
       "57914      2018.0      2022.0        NaN    2020.0  \n",
       "57932      2020.0         NaN        NaN    2018.0  \n",
       "\n",
       "[45452 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now create a dataframe that has no duplicates\n",
    "# Also remove entires, where ALS_TAVA_3 or ALS_METS is not existing as these are mainly on the border of the country and \n",
    "# data is incomplete\n",
    "als_list = als_list[als_list['ALS_TAVA_3'].notnull()]\n",
    "als_list = als_list[als_list['ALS_METS'].notnull()]\n",
    "als_list = als_list.drop_duplicates(subset = ['NR'])\n",
    "als_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3468f1da",
   "metadata": {},
   "source": [
    "### Note on the point clouds accessible on Estonian Land Board website\n",
    "Each year Estonian Land Board collects three types of ALS data:\n",
    "1. TAVA - regular aerial laser scanning of quarter of Estonia in spring (no-leaf) at 2000 or 2600 m with 2.1 p/m2.\n",
    "2. METS - aerial laser scanning of quarter of Estonia in the summer (leaf-on) at 3100 m and 0.8 p/m2.\n",
    "3. MADAL - annual aerial laser scanning of Estonian cities at 1200 m and 18 p/m2 (sometimes 3,5 p/m2). Note - some of these point clouds also include some forested areas.\n",
    "\n",
    "This notebook iterates over point cloud id-s marking 1:2000 map squares and sees if spring data for this area exists from the ALS 4th round taking place 2021-2024. If not, it downloads the data from the 3rd round that took place 2017-2020. It also downloads the newest point cloud from summer laser scanning.\n",
    "\n",
    "### Using the spring and summer scans\n",
    "Tava/regular point clouds have much higer point density - 3.5 p/m. However, they are acquired in spring when there are no leaves on the trees. Therefore, if I were to use only this type, the comparison of canopy gap retrieved from ICESat-2 transect showing leaf-on would differ.\n",
    "\n",
    "I have decided to download point clouds both acquired in spring and in the summer and test the canopy gap estimates from ICESat-2 data acquired during the respective season. This means, ICESat-2 data acquired between May and September are compared to data from point clouds acquired in the summer, while ICESat-2 transects acquired between October and April are compared to ALS data acquired in spring.\n",
    "\n",
    "### If and how to use the point clouds of urban areas\n",
    "Every year a much denser point clouds are made for urban areas, which however also include some forest. Currently, I have 1463 map squares which have forest and one or more ICESat-2 transects. This would allow test the methodology with much higer point density. This is not currently implemented.\n",
    "\n",
    "### The following function does:\n",
    "1. Iterate over dataframe row by row\n",
    "2. Saves the NR field as variable to keep the map square identifier\n",
    "3. Checks if field ALS_TAVA is NULL. If no, the tava_year is taken from field ALS_TAVA_4. Otherwise, the tava_year is taken from ALS_TAVA_4.\n",
    "3. Creates the file names for the laz files to be saved both for 'tava' and 'mets' files such as: map_square_nr_year_type.laz\n",
    "4. Creates the url for downloading the laz file\n",
    "5. Creates an empty .laz file for each type on the external harddrive\n",
    "6. Writes the .laz file retrieved from the Estonian Land Board to the empty file.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0055df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files already exist:  377651\n",
      "files already exist:  377652\n",
      "files already exist:  377655\n",
      "files already exist:  378651\n"
     ]
    }
   ],
   "source": [
    "# folder to store saved laz files\n",
    "data_loc = 'Z:\\\\Thesis\\\\Data\\\\ALS_data\\\\'\n",
    "df = als_list\n",
    "for iindex, row in df[:10].iterrows():\n",
    "    \n",
    "    tava_year = 0\n",
    "    if pd.isna(row['ALS_METS']):\n",
    "        # arbitrary year - will not find file with this year anyway\n",
    "        mets_year = 0\n",
    "    else:\n",
    "        mets_year = int(row['ALS_METS'])\n",
    "    \n",
    "    map_sq = row['NR']\n",
    "    \n",
    "    \n",
    "    if pd.isna(row['ALS_TAVA_4']):\n",
    "        # year is ALS_TAVA_3\n",
    "        tava_year = int(row['ALS_TAVA_3'])\n",
    "    else:\n",
    "        # year is ALS_TAVA_4\n",
    "        tava_year = int(row['ALS_TAVA_4'])\n",
    "        \n",
    "        \n",
    "    tava_laz = str(map_sq) + \"_\" + str(tava_year) + '_tava.laz'\n",
    "    mets_laz = str(map_sq) + \"_\" + str(mets_year) + '_mets.laz'\n",
    "    \n",
    "    # create empty files to external hardrive\n",
    "    tava_file = data_loc + 'TAVA\\\\' + tava_laz\n",
    "    mets_file = data_loc + 'METS\\\\' + mets_laz\n",
    "    \n",
    "    \n",
    "    URL_TAVA = 'https://geoportaal.maaamet.ee/index.php?lang_id=1&plugin_act=otsing&kaardiruut=' + str(map_sq) + '&andmetyyp=lidar_laz_tava&dl=1&f=' + tava_laz + '&no_cache=6391a110f2c5b&page_id=614'\n",
    "    URL_METS = 'https://geoportaal.maaamet.ee/index.php?lang_id=1&plugin_act=otsing&kaardiruut=' + str(map_sq) + '&andmetyyp=lidar_laz_mets&dl=1&f=' + mets_laz + '&no_cache=6391a110f2bee&page_id=614'\n",
    "    \n",
    "    #print('\\n\\n', URL_TAVA)\n",
    "    #print('\\n', URL_METS)\n",
    "    \n",
    "    #print('\\n\\n', tava_file)\n",
    "    #print('\\n', mets_file)\n",
    "    \n",
    "    \n",
    "    if os.path.isfile(tava_file):\n",
    "        # check if mets file also exists\n",
    "        if os.path.isfile(mets_file):\n",
    "                # if it also exists, skip\n",
    "                print('files already exist: ', map_sq)\n",
    "                continue\n",
    "        else:\n",
    "            # if mets file doesn't exists, create it:\n",
    "            try:\n",
    "                open(mets_file, 'a').close()\n",
    "            except OSError:\n",
    "                print('Failed creating the mets file ', map_sq ,' ', iindex)\n",
    "\n",
    "            try:\n",
    "                request.urlretrieve(URL_METS, mets_file)\n",
    "            except error.HTTPError as e:\n",
    "                # Return code error (e.g. 404, 501, ...)\n",
    "                print('HTTPError: {}'.format(e.code))\n",
    "    else:\n",
    "        # if tava file doesn't exist create it\n",
    "        try:\n",
    "            open(tava_file, 'a').close()\n",
    "        except OSError:\n",
    "            print('Failed creating the tava file ', map_sq)\n",
    "        try:\n",
    "            #conn = request.urlopen(URL_TAVA)\n",
    "            request.urlretrieve(URL_TAVA, tava_file)\n",
    "            \n",
    "        except error.HTTPError as e:\n",
    "            # Return code error (e.g. 404, 501, ...)\n",
    "            # ...\n",
    "            print('HTTPError: {}'.format(e.code))\n",
    "        \n",
    "        \n",
    "        # also check here if mets file already exists\n",
    "        if os.path.isfile(mets_file):\n",
    "                # if it also exists, skip\n",
    "                continue\n",
    "        else:\n",
    "            # if mets file doesn't exists, create it:\n",
    "            try:\n",
    "                open(mets_file, 'a').close()\n",
    "            except OSError:\n",
    "                print('Failed creating the mets file ', map_sq)\n",
    "            #else:\n",
    "                #print(map_sq, ' mets created')\n",
    "                # Download the laz file\n",
    "            try:\n",
    "                request.urlretrieve(URL_METS, mets_file)\n",
    "            except error.HTTPError as e:\n",
    "                # Return code error (e.g. 404, 501, ...)\n",
    "                print('HTTPError: {}'.format(e.code))\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92cdd33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
